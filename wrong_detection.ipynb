{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " import the necessary libraries: OpenCV (cv2) for image processing, NumPy for numerical operations, and TensorFlow (tf) for deep learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('C:\\\\Users\\\\d3vsh\\\\Downloads\\\\New folder\\\\rock_paper_scissors_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loads a pre-trained deep learning model from the specified file path. this is the model i trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image_path = 'C:\\\\Users\\\\d3vsh\\\\Downloads\\\\New folder\\\\11.jpg'  \n",
    "input_image = cv2.imread(input_image_path)\n",
    "input_image = cv2.cvtColor(input_image, cv2.COLOR_BGR2RGB)\n",
    "input_image_resized = cv2.resize(input_image, (64, 64)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "specify the path to an input image and load it using OpenCV. It also converts the image from BGR color format (used by OpenCV) to RGB format.\n",
    "python\n",
    "\n",
    "resizes the input image to a size of 64x64 pixels. The pre-trained model expects input images of this size.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = tf.convert_to_tensor(input_image_resized)\n",
    "input_tensor = tf.expand_dims(input_tensor, axis=0)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "convert the resized input image into a TensorFlow tensor and expand its dimensions to match the input shape expected by the model. The model expects a batch of images as input, so we add an extra dimension for the batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 13s 13s/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(input_tensor)\n",
    "\n",
    "\n",
    "class_labels = ['paper', 'rock', 'scissors']\n",
    "\n",
    "\n",
    "predicted_class_index = np.argmax(predictions)\n",
    "\n",
    "\n",
    "predicted_probability = predictions[0][predicted_class_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "uses the pre-trained model to make predictions on the input image and stores the result in the predictions variable.\n",
    "defines a list of class labels that correspond to the categories the model can predict\n",
    "line finds the index of the class with the highest predicted probability from the predictions array.\n",
    "extracts the predicted probability of the class with the highest probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if predicted_probability > 0.8:  \n",
    "    label = class_labels[predicted_class_index]\n",
    "    color = (0, 255, 0)  \n",
    "\n",
    "    \n",
    "    height, width, _ = input_image.shape\n",
    "    x1, y1, x2, y2 = 50, 50, 150, 150 \n",
    "    cv2.rectangle(input_image, (x1, y1), (x2, y2), color, 2)\n",
    "    cv2.putText(input_image, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "checks if the predicted probability of the winning class is greater than 0.8 (80%). This threshold is used to decide whether to annotate the image or not.\n",
    "predicted probability is high enough, it assigns a label (e.g., 'paper', 'rock', 'scissors') to the label variable and sets the color for annotation to green (0, 255, 0)\n",
    "obtain the height and width of the input image and define coordinates (x1, y1) and (x2, y2) to draw a rectangle around the region of interest (ROI).\n",
    "draw a rectangle and add text annotation to the input image to indicate the predicted class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_image_path = 'C:\\\\Users\\\\d3vsh\\\\Downloads\\\\New folder\\\\output_image111.jpg'  \n",
    "cv2.imwrite(output_image_path, cv2.cvtColor(input_image, cv2.COLOR_RGB2BGR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "line saves the annotated input image with the bounding box and label as an output image in a specified path."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
